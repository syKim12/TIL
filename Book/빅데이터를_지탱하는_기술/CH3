구조화 데이터: 스키마가 명확하게 정의된 데이터
- 스키마: 테이블의 칼럼 명과 데이터형, 테이블 간의 관계

스키마리스 데이터: 기본 서식은 있지만 스키마가 정의 안됨
- 스키마리스 데이터: CSV, JSON, XML 등의 데이터는 서식은 정해져 있지만, 칼럼수와 데이터 형은 명확하지 않다.

데이터 구조화의 파이프라인
- 분산 스토리지에 수집된 데이터는 명확한 스키마를 가지고 있지 않기도 하므로 SQL로 집계할 수 없다
- 따라서 먼저 스키마를 명확하게 한 테이블 형식의 '구조화 데이터'로 변환하는 것
- 일반적으로 구조화 데이터는 데이터의 압축률을 높이기 위해 열 지향 스토리지로 저장

열 지향 스토리지의 작성
- MPP 데이터베이스는 사용자가 상세를 몰라도 괜찮지만, Hadoop에서는 사용자가 직접 열지향 스토리지 형식을 선택하고 원하는 쿼리 엔진에서 집계 가능
- Apache Parquet: 스키마리스에 가까운 데이터 구조로 되어있어 JSON 같은 데이터도 저장 가능

분산 시스템의 구성요소
- 분산 파일 시스템: HDFS
- 리소스 관리자: YARN
- 분산 데이터 처리: MapReduce

HDFS와 YARN
- HDFS: Hadoop에서 처리되는 데이터 대부분은 분산 파일 시스템은 HDFS에 저장
  - 분산 시스템의 스토리지를 관리하여 데이터가 항상 여러 컴퓨터에 복사되도록 함
- YARN: CPU나 메모리 등의 계산 리소스는 리소스 매니저인 YARN에서 관리
  - YARN은 애플리케이션이 사용하는 CPU 코어와 메모리를 '컨테이너'라고 불리는 단위로 관리
  - Hadoop에서 분산 애플리케이션을 실행하면 YARN이 클러스터 전체의 부하를 보고 비어있는 호스트부터 컨테이너를 할당
  - 중요하지 않은 배치 처리에는 낮은 우선 순위를 부여함으로써 아무도 리소스를 사용하지 않을 경우에만 실행되도록 한다. 우선되는 작업부터 실행함으로써 한정된 뢰소슬르 낭비없이 활용하면서 데이터 처리 가능
  - cf) YARN의 컨테이너는 도커 처럼 OS 수준의 가상화 기술이 아닌 어떤 호스트에서 어떤 프로세스를 실행시킬지 결정하는 애플리케이션 수준의 기술

MapReduce와 Hive
- MapReduce: YARN상에서 동작하는 분산 애플리케이션 중 하나이며, 분산 시스템에서 데이터 처리를 실행하는데 사용
  - 임의의 자바 프로그램을 실행시킬 수 있기 때문에 비구조화 데이터를 가공하는데 적합
  - 한 번 실행하면 분산 파일 시스템에서 대량의 데이터를 읽을 수 있지만, 작은 프로그램을 실행하려면 오버헤드가 너무 크므로 몇 초 안에 끝나버리는 쿼리실행에는 부적합
  - 데이터 처리의 스테이지가 바뀔 때 대기 시간이 있어 복잡한 쿼리에서는 대기 시간만 증가한다.
- Hive: 데이터 집계를 위해 설계된 쿼리 엔진
  - 시간이 걸리는 배치 처리에는 적합하나 애드 혹 쿼리를 여러번 실행하는 데는 부적합.
  
Hive on Tez
- 1회의 MapReduce 스테이지가 끝날 때 까지 다음 처리를 진행할 수 없는 MapReduce와 달리, Tez는 스테이지 종료를 기다리지 않고 처리가 끝난 데이터를 차례대로 후속 처리에 전달함으로써 쿼리 전체의 실행시간 단축

대화형 쿼리엔진
- MapReduce와 Tez는 장시간의 배치 처리를 가정해 한정된 리소스를 유효하게 활용하도록 설계
- 대화형 쿼리엔진은 순간 최대 속도를 높이기 위해 모든 오버헤드가 제거되어 사용할 수 있는 리소스를 최대로 활용해 쿼리 실행 -> MPP 데이터베이스와 비교해도 손색없는 응답시간
- Presto와 Impara는 YARN과 같은 범용 리소스 관리자를 사용하지 않고, SQL 실행만 특화한 독자적인 분산 처리 구현, MPP 데이터베이스처럼 멀티 코어를 활용하며 많은 데이터 처리를 병렬화함으로써 고속화 실현

하둡 + 쿼리엔진
- Hive: 대량의 비구조화 데이터를 가공하는 무거운 배치처리에는 높은 Throughput( 처리량)으로 리소스 활용하는 hive
- Implala or Presto: 완성한 구조화 데이터를 대화식으로 집계하고자 할 때는 지연이 적은 대화형 쿼리엔진

Spark
- 특징: 대량의 메모리 활용해 고속화 실현
  - MapReduce and Tez: 데이터 처리의 대부분을 디스크의 읽고 쓰기에 사용. 데이터 처리의 과정에서 만들어진 중간 데이터는 디스크로 기록
  - Spark: 컴퓨터가 비정상 종료하면 중간까지 처리한 중간 데이터는 사라지지만, 그럴 때는 처리를 다시 시도하여 잃어버린 중간 데이터를 다시 만든다. 중간 데이터를 의도적으로 디스크 상에 캐시하는 것도 가능
  
MapReudce 대체
- 스파크는 Hadoop을 대체하는 것이 아니라 MapReduce를 대체하는 것
  - e.g.) 분산 파일 시스템인 HDFS나 리소스 관리자인 YARN은 Spark에서도 사용. 분산스토리지로 amazon s3를 이용하는 것도 가능.
  
데이터 마트 구축의 파이프라인
- 분산 스토리지에 저장된 데이터를 구조화하고 열 지향 스토리지 형식으로 저장, 이 때 부하가 큰 처리가 되기 때문에 Hive 이용
- 완성된 구조화 데이터를 결합, 집계하고 비정규화 테이블로 데이터 마트에 써서 내보냄, 이 때 Presto를 사용함으로써 실행 시간 단축 가능
- Hive에서 만든 각 테이블의 정보는 'Hive 메타 스토어'라고 불리는 특별한 데이터베이스에 저장

Hive에 의한 구조화 데이터 작성
- 외부 테이블: Hive 외부에 있는 특정 파일을 참고해 마치 테이블이 존재하는 것처럼 읽어 들이기 위해 저장
- 테이블을 열 지향 스토리지 형식인 ORC 형식으로 변환
  - ORC 형식으로의 변환에는 시간이 다소 걸리지만 변환 후 테이블 집계는 빠르다.
- Hive로 비정규화 테이블을 만드는데 오랜 시간이 걸리는 경우가 많으므로 효율적인 쿼리 작성.
    - 서브 쿼리 안에서 레코드 줄이기
      - Hive는 데이터 베이스가 아닌 데이터 처리를 위한 배치 처리 구조
      - 서브 쿼리 안에서 팩트 테이블을 작게하는 것이 좋으며, '초기에 팩트 테이블을 작게 하는 것'이 빅데이터 집계에서 중요하다.
    - 데이터 편향 방지하기
      - 예를 들어 하나의 웹페이지만 100배의 접속이 발생한다면 해당 웹페이지의 distinct count만이 극단적으로 늦어지고, 전체적인 쿼리 실행 시간이 늘어난다.
      - 분산 시스템의 성능을 발휘하기 위해 데이터 편차를 최대한 없애고, 모든 노드에 데이터가 균등하게 분산되도록 해야한다.
      - SELECT DISTINCT로 중복을 제거함으로써 부하를 잘 분산하며 데이터 양을 줄일 수 있다.
      
Presto 구조
특징: 
- 플러그인 가능한 스토리지
  - 일반적인 MPP 데이터베이스에서는 스토리지와 컴퓨팅 노드가 밀접하게 결합되어 있어 처음부터 데이터를 로드하지 않으면 집계를 시작할 수 없다.
  - Presto는 전용 스토리지를 갖고 있지 않으므로 Hive와 마찬가지로 다양한 데이터 소스에서 직접 데이터를 읽어 들인다.
  - Presto는 다수의 컴퓨터에서 실행되는 분산 시스템이며, 하나의 코디네이터와 여러 워커로 구성. 
  - 쿼리는 Presto CLI 등의 클라이언트에서 코디네이터로 전송 -> 코디네이터는 쿼리를 분석하고  실행계획 수립해 워커에게 처리 분배
  - Hive 메타 스토어에 등록된 테이블을 가져올 수 있으므로 Hive에서 만든 구조화 데이터를 좀 더 집계하는 등의 목적에 적합
  - 성능 최대 발휘위해 스토리지가 열 지향 데이터 구조로 되어있어야 한다. 
  - 데이터 로딩 속도를 높이기 위해 클러스터를 분산 스토리지와 네트워크의 가까운 곳에 설치한 후에 그것들을 가능한 한 고속 네트워크에 연결하도록 해야함
  - hive 메타 스토어 이외에도 다양한 데이터 소스를 테이블로 참고 가능
- CPU 처리 최적화: 읽기와 코드 실행 병렬 처리
  - SQL 실행에 특화된 시스템으로 쿼리를 분석하여 최적의 실행계획을 생성하고, 그것을 자바의 바이트 코드로 변환한다.
	- Presto 클러스터는 Presto 만을 위해 항상 대기하고 있으며, 쿼리 실행에 컴퓨터의 모든 리소스를 사용, 리소스 부족하면 나중에 실행된 쿼리는 앞의 쿼리가 끝날 때까지 기다려야함. -> 지연 발생하므로 Presto 클러스터는 항상 여유있는 상태여야함
	- Presto 쿼리는 일단 실행되면 중간에 끼어들 수 없으므로 너무 큰 쿼리를 실행하면 안된다. 너무 큰 쿼리를 실행함으로써 대부분의 리소스가 사용되어 다른 쿼리를 실행할 수 없게될수도. But 대부분 쿼리는 단시간 종료해 리소스 해제되므로 웬만해서는 문제 인지할 수 없음
- 인 메모리 처리에 의한 고속화: 쿼리 실행에는 가급적 대화형 쿼리 엔진 사용
	- Hive와 달리 Presto는 쿼리의 실행 과정에서 디스크에 쓰기를 하지 않음. 모든 데이터 처리를 메모리상에서 실시하고 메모리가 부족하면 여유가 생길 때까지 기다리거나 오류로 실패한다. -> 설정 변경 등으로 메모리 할당을 늘리거나 쿼리를 다시 작성해 메모리 소비를 줄여야한다.
	- 취급하는 데이터 양이 많아도 그에 비례하여 메모리 소비가 늘어나지는 않는다.
	- 대부분 쿼리에 있어 중간 데이터를 디스크에 쓰는 것은 쓸데없는 오버헤드다
	- 따라서 메모리 상에서 할 수 있는 것은 메모리 상에서 실행하고 디스크가 있어야하는 일부 데이터 처리만 Hive에서 하는 것이 효율적.
	- 대규모 배치처리와 거대한 테이블 결합 등에는 디스크 활용, 단시간 쿼리 실행에는 대화형 쿼리엔진 사용하는 것이 효율적
- 분산 결합과 브로드캐스트 결합
	- 분산 결합: 같은 키를 갖는 데이터는 동일한 노드, 분산결합에서는 노드간의 데이터 전송을 위히ㅏㄴ 네트워크 통신이 발생하기 때문에 종종 쿼리의 지연을 초래한다.
	- 브로드캐스트 결합: 결합하는 테이블의 모든 데이터가 각 노드에 복사된다. 한쪽 테이블이 충분히 작은 경우 분산 결합이 아닌 브로드캐스트 결합을 통해 처리속도를 고속화할 수 있음
- 열 지향 스토리지 집계: Presto에 의한 고속 집계
	


